{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/01 15:10:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "curr_path = str(Path(os.getcwd()).parent)\n",
    "sys.path.append(curr_path)\n",
    "from scripts.sa2_age_allocation import *\n",
    "from scripts.constants import *\n",
    "from scripts.load import *\n",
    "from scripts.transform import *\n",
    "from scripts.read import *\n",
    "from scripts.misc_changes import *\n",
    "from scripts.external_etl import *\n",
    "from scripts.join import *\n",
    "from scripts.plotting import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.column import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import geopandas as gpd\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "# start a spark session\n",
    "spark = create_spark()\n",
    "PREFIX = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_transactions = read_curated_transactions_all(spark, PREFIX)\n",
    "external_data = pd.read_csv(\"../data/curated/external_joined_data.csv\")\n",
    "consumer_external = spark.read.parquet(\"../data/curated/consumer_external_join.parquet/\")\n",
    "# external_data = read_curated_external_join(spark, PREFIX)\n",
    "# external_data = external_data.astype({SA2_CODE: \"str\", POSTCODE: \"str\"})\n",
    "# external_data[POSTCODE] = external_data[POSTCODE].astype(int)\n",
    "# sa2_2021_mapping = pd.read_csv(\"../data/raw/CG_SA2_2016_SA2_2021.csv\")\n",
    "# postcodes_to_sa2_2016 = pd.read_csv(\"../data/raw/australian_postcodes.csv\")\n",
    "# consumer_external = read_curated_consumer_external_join(spark, PREFIX)\n",
    "# consumer_data = read_curated_consumer_join(spark, PREFIX)\n",
    "# external_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = read_curated_merchant_fraud(spark, PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PAR1\u0015\u0004\u0015�\\a\u0015�\\a\u0015����\u0002&lt;\u0015z\u0015\u0004\u0000\u0000�\u0003�C��Ӊ\u0004\u0000\u0000\u0000��K\\a\u0000\u0000\u0000�� S\u0013\u0000\u0000\u0000�W%+\u0015\u0000\u0000\u0000;�׃\u0005\u0000\u0000\u0000zu�s\u0003\u0000\u0000\u0000��ȶ\u0015\u0000\u0000\u0000�\u0010_\u0013\u0000\u0000\u0000��`�\u0001(�\u0012W��\u0016\u0000\u0000\u0000U��\\a</th></tr>\n",
       "<tr><td>\u0000\u0000\u0000M��G\u0017\u0000\u0000\u0000to��\u0010\u0000...</td></tr>\n",
       "<tr><td>\u0006C�\u000f\u0001\u0010(�ײ\u0002\u0000\u0000\u0000�lT\u0016...</td></tr>\n",
       "<tr><td>\u0000\u0000\u0000&lt;;!g\u0001\\b\u00105Z�N\u0006\u0001...</td></tr>\n",
       "<tr><td>\u0000\u0000\u00002021-11-28\u0019\u000e\\f...</td></tr>\n",
       "<tr><td>8\u0005\u000e\u00001\u0011\u000e\u00001\u0001T.*\u0000\\f1-21</td></tr>\n",
       "<tr><td>*\\f1-102b\u0000\u00000.8\u0000\u00100...</td></tr>\n",
       "<tr><td>*\u0005T.�\u0000\u000002�\u00006T\u0000\\b2...</td></tr>\n",
       "<tr><td>b\u0001\\v\u0019~\\b2-0\u0001\u0011\u0015\u001c\u0001T...</td></tr>\n",
       "<tr><td>\u0001\u0011.&amp;\u0001\u00002\u0011�\u00001\u0001T5�\u0001&#x27;...</td></tr>\n",
       "<tr><td>��oo�A@��#\\aw�E@�...</td></tr>\n",
       "<tr><td>�e�+A@�L/</td></tr>\n",
       "<tr><td>\u0011+A@*J\u001f}\u0006�C@�a\u001dR\u0000...</td></tr>\n",
       "<tr><td>&gt;(�D?@T���\u001a�=@R\\b...</td></tr>\n",
       "<tr><td>9@hD.V��:@ J�\u001c�\u0012=...</td></tr>\n",
       "<tr><td>.\u001f�\u0001=@:�y�\u000f%&lt;@��5...</td></tr>\n",
       "<tr><td>2021-03-25\u0019\u0018</td></tr>\n",
       "<tr><td>2022-02-27\u0015\u0002\u0019\u0016\u0000\u0000\u0019...</td></tr>\n",
       "<tr><td>%\u0002\u0018\u0011fraud_probabi...</td></tr>\n",
       "<tr><td>2022-02-27\u0018</td></tr>\n",
       "<tr><td>2021-03-25\u0000\u0019</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---------------------------------------------------------------------------------------------------------------+\n",
       "|PAR1\u0015\u0004\u0015�\\a\u0015�\\a\u0015����\u0002<\u0015z\u0015\u0004\u0000\u0000�\u0003�C��Ӊ\u0004\u0000\u0000\u0000��K\\a\u0000\u0000\u0000�� S\u0013\u0000\u0000\u0000�W%+\u0015\u0000\u0000\u0000;�׃\u0005\u0000\u0000\u0000zu�s\u0003\u0000\u0000\u0000��ȶ\u0015\u0000\u0000\u0000�\u0010_\u0013\u0000\u0000\u0000��`�\u0001(�\u0012W��\u0016\u0000\u0000\u0000U��\\a|\n",
       "+---------------------------------------------------------------------------------------------------------------+\n",
       "|                                                                                           \u0000\u0000\u0000M��G\u0017\u0000\u0000\u0000to��\u0010\u0000...|\n",
       "|                                                                                           \u0006C�\u000f\u0001\u0010(�ײ\u0002\u0000\u0000\u0000�lT\u0016...|\n",
       "|                                                                                           \u0000\u0000\u0000<;!g\u0001\\b\u00105Z�N\u0006\u0001...|\n",
       "|                                                                                           \u0000\u0000\u00002021-11-28\u0019\u000e\\f...|\n",
       "|                                                                                           8\u0005\u000e\u00001\u0011\u000e\u00001\u0001T.*\u0000\\f1-21|\n",
       "|                                                                                           *\\f1-102b\u0000\u00000.8\u0000\u00100...|\n",
       "|                                                                                           *\u0005T.�\u0000\u000002�\u00006T\u0000\\b2...|\n",
       "|                                                                                           b\u0001\\v\u0019~\\b2-0\u0001\u0011\u0015\n",
       "\u0001T...|\n",
       "|                                                                                           \u0001\u0011.&\u0001\u00002\u0011�\u00001\u0001T5�\u0001'...|\n",
       "|                                                                                           ��oo�A@��#\\aw�E@�...|\n",
       "|                                                                                                      �e�+A@�L/|\n",
       "|                                                                                           \u0011+A@*J\u001f}\u0006�C@�a\n",
       "R\u0000...|\n",
       "|                                                                                           >(�D?@T���\u001a�=@R\\b...|\n",
       "|                                                                                           9@hD.V��:@ J�\n",
       "�\u0012=...|\n",
       "|                                                                                           .\u001f�\u0001=@:�y�\u000f%<@��5...|\n",
       "|                                                                                                   2021-03-25\u0019\u0018|\n",
       "|                                                                                           2022-02-27\u0015\u0002\u0019\u0016\u0000\u0000\u0019...|\n",
       "|                                                                                           %\u0002\u0018\u0011fraud_probabi...|\n",
       "|                                                                                                    2022-02-27\u0018|\n",
       "|                                                                                                   2021-03-25\u0000\u0019|\n",
       "+---------------------------------------------------------------------------------------------------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transactions = round_dollar_values(spark.read.parquet(PREFIX+RAW_TRANSACTIONS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transactions.groupBy(MERCHANT_ABN, ORDER_DATETIME).agg(sum(DOLLAR_VALUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \".\"\n",
    "consumer_fraud = read_raw_consumer_fraud(spark, PREFIX)\n",
    "consumer_joined = read_curated_consumer_join(spark, PREFIX)\n",
    "raw_transactions = spark.read.parquet(\"../data/raw/raw_transactions/\")\n",
    "merchant_fraud = read_raw_merchant_fraud(spark, PREFIX)\n",
    "tbl_merchants = encode_revenue_level(read_mapped_industry_data(spark, PREFIX))\n",
    "tbl_merchants = tbl_merchants.withColumn(TAKE_RATE, col(TAKE_RATE).cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_features(df: DataFrame) -> DataFrame:\n",
    "    df = df.withColumns({\n",
    "        ORDER_DAY_OF_MONTH: dayofmonth(col(ORDER_DATETIME)),\n",
    "        ORDER_MONTH: month(col(ORDER_DATETIME)),\n",
    "        ORDER_YEAR: year(col(ORDER_DATETIME))\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_fraud_prob_column(df:DataFrame, new_column: str) -> DataFrame:\n",
    "    return df.withColumnRenamed(FRAUD_PROBABILITY, new_column)\n",
    "\n",
    "# perform log-transformation for fraud probabilities\n",
    "consumer_fraud = consumer_fraud.withColumn(FRAUD_PROBABILITY, log(col(FRAUD_PROBABILITY)))\n",
    "merchant_fraud = merchant_fraud.withColumn(FRAUD_PROBABILITY, log(col(FRAUD_PROBABILITY)))\n",
    "\n",
    "# rename fraud probability columns to relevant dataset name\n",
    "merchant_fraud = rename_fraud_prob_column(merchant_fraud, MERCHANT_FRAUD_PROB)\n",
    "consumer_fraud = rename_fraud_prob_column(consumer_fraud, CONSUMER_FRAUD_PROB)\n",
    "\n",
    "# extract the date features\n",
    "merchant_fraud = extract_date_features(merchant_fraud)\n",
    "consumer_fraud = extract_date_features(consumer_fraud)\n",
    "\n",
    "# transform the transaction columns to preserve only 2 dp\n",
    "# raw_transactions = raw_transactions.groupBy([MERCHANT_ABN, ORDER_DATETIME]).agg(avg(DOLLAR_VALUE).alias(DOLLAR_VALUE))\n",
    "raw_transactions = round_dollar_values(raw_transactions)\n",
    "raw_transactions = extract_date_features(raw_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.read.csv(\"../data/curated/postcode_to_sa2_map.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns to drop and that are categorical\n",
    "drop_cols = (NAME, ORDER_ID, USER_ID, ORDER_DATETIME)\n",
    "cat_cols = (MERCHANT_ABN, ORDER_YEAR, ORDER_MONTH, ORDER_DAY_OF_MONTH, INDUSTRY_TAGS)\n",
    "# cat_cols = (MERCHANT_ABN, INDUSTRY_TAGS)\n",
    "MERCHANT_JOIN_COLS = [MERCHANT_ABN, ORDER_YEAR, ORDER_MONTH, ORDER_DAY_OF_MONTH]\n",
    "# MERCHANT_JOIN_COLS = [MERCHANT_ABN, ORDER_DATETIME]\n",
    "LABEL = \"label\"\n",
    "LOWER_BOUND = 50.0\n",
    "UPPER_BOUND = 80.0\n",
    "FEATURES = \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the merchant-related columns with the transactions\n",
    "merchant_transactions = raw_transactions.join(merchant_fraud, on=MERCHANT_JOIN_COLS, how=OUTER_JOIN)\\\n",
    "    .join(tbl_merchants, on=[MERCHANT_ABN], how=INNER_JOIN)\n",
    "\n",
    "# drop uninformative columns\n",
    "merchant_transactions = merchant_transactions.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the merchant ABN, order datetime, and user ID as strings for string indexing \n",
    "merchant_transactions = merchant_transactions.withColumns({\n",
    "    MERCHANT_ABN: col(MERCHANT_ABN).cast(StringType()),\n",
    "    ORDER_DAY_OF_MONTH: col(ORDER_DAY_OF_MONTH).cast(StringType()),\n",
    "    ORDER_MONTH: col(ORDER_MONTH).cast(StringType()),\n",
    "    ORDER_YEAR: col(ORDER_YEAR).cast(StringType())\n",
    "})\n",
    "\n",
    "# merchant_transactions = merchant_transactions.withColumn(LABEL,\n",
    "#                         when(col(MERCHANT_FRAUD_PROB) <= LOWER_BOUND, NO)\\\n",
    "#                         .when(col(MERCHANT_FRAUD_PROB) >= UPPER_BOUND, YES)\\\n",
    "#                         .when(col(MERCHANT_FRAUD_PROB).isNull(), None)\\\n",
    "#                         .otherwise(MAYBE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merchant_transactions.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_merchant_fraud_probability(merchant_transactions: DataFrame):\n",
    "    \"\"\"\n",
    "    Predict the remaining unknown merchant fraud probabilities based on transactions and dollar value\n",
    "    Args:\n",
    "        merchant_transactions (DataFrame): Dataframe containing aggregated \n",
    "    Returns:\n",
    "        rf: Initialised Random Forest Regressor model\n",
    "        rf_model: Fitted Random Forest Regressor model\n",
    "        pred_df: Dataframe of predicted models\n",
    "    \"\"\"\n",
    "    INDEXED_COL = \"_indexed\"\n",
    "    DIFFERENCE = \"difference\"\n",
    "    PREDICTION = \"prediction\"\n",
    "    \n",
    "    LOWER_BOUND = 50.0\n",
    "    UPPER_BOUND = 80.0\n",
    "    cat_cols = (ORDER_YEAR, ORDER_MONTH, ORDER_DAY_OF_MONTH, INDUSTRY_TAGS)\n",
    "    input_assembler_cols = [DOLLAR_VALUE, TAKE_RATE, REVENUE_LEVEL, \n",
    "                            \"order_day_of_month_indexed\", \"order_month_indexed\", \"order_year_indexed\", \"industry_tags_indexed\"]\n",
    "\n",
    "    # merchant_abns = merchant_transactions.select(MERCHANT_ABN)\n",
    "    # merchant_abns = list(merchant_abns.distinct().rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "    print(\"PERFORM STRING INDEXING\")\n",
    "    for column in cat_cols:\n",
    "        col_indexer = StringIndexer(inputCol=column, outputCol=column+INDEXED_COL)\n",
    "        merchant_transactions = col_indexer.fit(merchant_transactions).transform(merchant_transactions)\n",
    "\n",
    "    print(\"PERFORM VECTOR ASSEMBLING\")\n",
    "    assembler = VectorAssembler(inputCols=input_assembler_cols, outputCol=\"features\")\n",
    "    merchant_fraud_transactions = assembler.transform(merchant_transactions)\n",
    " \n",
    "    print(\"SPLIT DATA INTO KNOWN AND UNKNOWN FRAUD PROBABILITIES\")\n",
    "    train_test_merchants = merchant_fraud_transactions.where(col(MERCHANT_FRAUD_PROB).isNotNull())\n",
    "    to_predict_merchants = merchant_fraud_transactions.where(col(MERCHANT_FRAUD_PROB).isNull())\n",
    "\n",
    "    print(\"SPLIT KNOWN PROBABILITIES INTO TRAIN-TEST SET\")\n",
    "    train_merchants, test_merchants = train_test_merchants.randomSplit([0.9, 0.1], seed=42)\n",
    "    # print(train_merchants.count())\n",
    "    # print(test_merchants.count())\n",
    "\n",
    "    print(\"INITIALISE RFR MODEL\")    \n",
    "    rf = RandomForestRegressor(featuresCol=FEATURES, labelCol=MERCHANT_FRAUD_PROB)\n",
    "    print(\"FIT RFR MODEL WITH TRAIN SET\")\n",
    "    rf_model = rf.fit(train_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "    print(\"TRANSFORM AND PREDICT RFR MODEL WITH TEST SET\")\n",
    "    predictions = rf_model.transform(test_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "\n",
    "    print(\"TRANSFORM THE PREDICTIONS TO EXP OF PREDICTIONS\")\n",
    "    pred_df = predictions.withColumns({\n",
    "        PREDICTION: exp(col(PREDICTION)),\n",
    "        MERCHANT_FRAUD_PROB: exp(col(MERCHANT_FRAUD_PROB))})\n",
    "    pred_df = pred_df.withColumn(DIFFERENCE, col(PREDICTION) - col(MERCHANT_FRAUD_PROB))\n",
    "\n",
    "    print(\"RETURN ALL VALUES NEEDED\")\n",
    "    return rf, rf_model, pred_df, to_predict_merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, rf_model, diff, predicting_merchants = predict_merchant_fraud_probability(merchant_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION = \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_evaluator = RegressionEvaluator(labelCol=MERCHANT_FRAUD_PROB, predictionCol=PREDICTION, metricName=\"mae\")\n",
    "mae_evaluator.evaluate(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_evaluator = RegressionEvaluator(labelCol=MERCHANT_FRAUD_PROB, predictionCol=PREDICTION, metricName=\"r2\")\n",
    "r2_evaluator.evaluate(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = rf_model.transform(predicting_merchants)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.withColumn(\"prediction\", exp(col(\"prediction\")))\n",
    "pred_df = pred_df.drop(MERCHANT_FRAUD_PROB)\n",
    "pred_df = pred_df.withColumnRenamed(existing=PREDICTION, new=MERCHANT_FRAUD_PROB)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_assembler_cols = [DOLLAR_VALUE, TAKE_RATE, REVENUE_LEVEL, f\"{MERCHANT_ABN}_indexed\", \"order_day_of_month_indexed\", \"order_month_indexed\", \"order_year_indexed\", \"industry_tags_indexed\"]\n",
    "# input_assembler_cols = [DOLLAR_VALUE, TAKE_RATE, REVENUE_LEVEL, \"merchant_abn_indexed\", \"industry_tags_indexed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [col for col in pred_df.columns if \"_indexed\" in col]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = pred_df.drop(*drop_cols)\n",
    "new_predictions = new_predictions.drop(FEATURES)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions = merchant_transactions.where(col(MERCHANT_FRAUD_PROB).isNotNull())\n",
    "fraud_transactions = fraud_transactions.withColumn(MERCHANT_FRAUD_PROB, exp(col(MERCHANT_FRAUD_PROB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions = fraud_transactions.union(new_predictions)\n",
    "all_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_transactions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions = all_transactions.where(col(MERCHANT_FRAUD_PROB) < 60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin Modelling Merchant Fraud Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_merchants = merchant_fraud_transactions.where(col(MERCHANT_FRAUD_PROB).isNotNull())\n",
    "to_predict_merchants = merchant_fraud_transactions.where(col(MERCHANT_FRAUD_PROB).isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merchants, test_merchants = train_test_merchants.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train and test using logistic regression model\n",
    "# lr = LogisticRegression(featuresCol=FEATURES, labelCol=MERCHANT_FRAUD_PROB)\n",
    "# lr_model = lr.fit(train_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "# predictions = lr.transform(test_merchants(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test using decision tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = DecisionTreeRegressor(featuresCol=FEATURES, labelCol=MERCHANT_FRAUD_PROB)\n",
    "dt_model = dt.fit(train_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "dt_predictions = dt_model.transform(test_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "dt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test using random forest\n",
    "rf = RandomForestRegressor(featuresCol=FEATURES, labelCol=MERCHANT_FRAUD_PROB)\n",
    "rf_model = rf.fit(train_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "predictions = rf_model.transform(test_merchants.select(FEATURES, MERCHANT_FRAUD_PROB))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(math.exp(3.3171763572147634))\n",
    "# print(math.exp(3.3656943036441676))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = predictions.withColumn(\"difference\", col(\"prediction\") - col(MERCHANT_FRAUD_PROB))\n",
    "diff = diff.withColumn(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = dt_predictions.withColumn(\"difference\", col(\"prediction\") - col(MERCHANT_FRAUD_PROB))\n",
    "# diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast30034",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
